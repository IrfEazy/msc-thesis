{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e47e11e2",
   "metadata": {
    "papermill": {
     "duration": 0.007277,
     "end_time": "2024-12-12T16:26:14.553663",
     "exception": false,
     "start_time": "2024-12-12T16:26:14.546386",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Multi-Class Classification with Machine Learning\n",
    "In this notebook, we will explore various machine learning models to solve a multi-class classification problem. We will evaluate and compare the performance of different algorithms on the dataset.\n"
   ]
  },
  {
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T16:26:14.569199Z",
     "iopub.status.busy": "2024-12-12T16:26:14.568776Z",
     "iopub.status.idle": "2024-12-12T16:26:17.993533Z",
     "shell.execute_reply": "2024-12-12T16:26:17.992503Z"
    },
    "papermill": {
     "duration": 3.435545,
     "end_time": "2024-12-12T16:26:17.996431",
     "exception": false,
     "start_time": "2024-12-12T16:26:14.560886",
     "status": "completed"
    },
    "tags": []
   },
   "cell_type": "code",
   "source": [
    "import ast\n",
    "import json\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from skmultilearn.model_selection import iterative_train_test_split\n",
    "from tqdm import tqdm\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from preprocess_functions import build_tree, extract_keys, merge_all_trees_with_counts, preprocess_texts\n",
    "from utils import CalibratedLabelRankClassifier, ChainOfClassifiers, LabelPowersetClassifier, \\\n",
    "    assess_models, prune_and_subsample, ConditionalDependencyNetwork, MetaBinaryRelevance\n"
   ],
   "id": "3725615c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "OVERWRITE = False\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "np.random.seed(RANDOM_STATE)\n",
    "random.seed(RANDOM_STATE)\n"
   ],
   "id": "30ed7102e0110c7f",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8074f464",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T16:26:18.012827Z",
     "iopub.status.busy": "2024-12-12T16:26:18.012308Z",
     "iopub.status.idle": "2024-12-12T16:26:18.020759Z",
     "shell.execute_reply": "2024-12-12T16:26:18.019690Z"
    },
    "papermill": {
     "duration": 0.019672,
     "end_time": "2024-12-12T16:26:18.022881",
     "exception": false,
     "start_time": "2024-12-12T16:26:18.003209",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "INIT_POINTS = 1\n",
    "N_ITER = 5\n",
    "TEST_SIZE = 2e-1\n",
    "\n",
    "BASE_CLASSIFIERS = {\n",
    "    'logistic_regression': LogisticRegression(solver='liblinear', random_state=RANDOM_STATE),\n",
    "    'gaussian_nb': GaussianNB(),\n",
    "    'decision_tree': DecisionTreeClassifier(random_state=RANDOM_STATE),\n",
    "    'random_forest': RandomForestClassifier(random_state=RANDOM_STATE),\n",
    "    'xgb': XGBClassifier(random_state=RANDOM_STATE)\n",
    "}\n",
    "\n",
    "COLAB_PATH = Path('/content/drive/MyDrive')\n",
    "KAGGLE_PATH = Path('/kaggle/input')\n",
    "LOCAL_PATH = Path('./')\n",
    "\n",
    "# Step 1: Check if running in Google Colab\n",
    "try:\n",
    "    import google.colab\n",
    "\n",
    "    DATA_PATH = COLAB_PATH / Path('data')\n",
    "    MODELS_PATH = COLAB_PATH / Path('models')\n",
    "except ImportError:\n",
    "    # Step 2: Check if running in Kaggle\n",
    "    try:\n",
    "        import kaggle_secrets\n",
    "\n",
    "        DATA_PATH = KAGGLE_PATH\n",
    "        MODELS_PATH = KAGGLE_PATH\n",
    "    except ImportError:\n",
    "        # Step 3: Default to local Jupyter Notebook\n",
    "        DATA_PATH = LOCAL_PATH / Path('data')\n",
    "        MODELS_PATH = LOCAL_PATH / Path('models')\n",
    "\n",
    "GLOVE_6B_PATH = MODELS_PATH / Path('glove-embeddings')\n",
    "THREAT_TWEETS_PATH = DATA_PATH / Path('tweets-dataset-for-cyberattack-detection')\n",
    "\n",
    "GLOVE_6B_300D_TXT = GLOVE_6B_PATH / Path('glove.6B.300d.txt')\n",
    "THREAT_TWEETS_CSV = THREAT_TWEETS_PATH / Path('tweets_final.csv')\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "papermill": {
     "duration": 0.006302,
     "end_time": "2024-12-12T16:26:18.048634",
     "exception": false,
     "start_time": "2024-12-12T16:26:18.042332",
     "status": "completed"
    },
    "tags": []
   },
   "cell_type": "markdown",
   "source": [
    "## 1. Introduction\n",
    "\n",
    "In this notebook, we are going to solve a multi-class classification problem using different machine learning models. Our goal is to predict the class of each sample based on the input features.\n"
   ],
   "id": "02878d64"
  },
  {
   "metadata": {
    "papermill": {
     "duration": 0.006199,
     "end_time": "2024-12-12T16:26:18.061625",
     "exception": false,
     "start_time": "2024-12-12T16:26:18.055426",
     "status": "completed"
    },
    "tags": []
   },
   "cell_type": "markdown",
   "source": [
    "## 2. Data Loading and Preprocessing\n",
    "We will load the dataset, inspect its structure, and preprocess it for machine learning models.\n"
   ],
   "id": "bc09f879"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Read the CSV file and process columns in one step\n",
    "threat_tweets = (\n",
    "    pd.read_csv(filepath_or_buffer=THREAT_TWEETS_CSV)\n",
    "    .assign(\n",
    "        tweet=lambda df: df['tweet'].apply(func=ast.literal_eval),\n",
    "        watson=lambda df: df['watson'].apply(func=ast.literal_eval)\n",
    "        .apply(func=lambda x: x.get('categories', []))\n",
    "        .apply(func=build_tree),\n",
    "        watson_list=lambda df: df['watson'].apply(func=extract_keys),\n",
    "    )\n",
    "    .query(expr='relevant == True')\n",
    "    .drop(labels=['relevant'], axis=1)\n",
    "    .dropna(subset=['text'], ignore_index=True)\n",
    ")\n",
    "\n",
    "threat_tweets.head()\n"
   ],
   "id": "2f76035997296746",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(f\"Number of CS related tweets:\\t{len(threat_tweets)}\")\n",
   "id": "1273c8994072c16c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "general_tree, visit_count = merge_all_trees_with_counts(trees=threat_tweets['watson'])\n",
   "id": "a3afc9058abe1111",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"The subcategories in 'technology and computing' are:\")\n",
    "for category in list(general_tree['technology and computing'].keys()):\n",
    "    print(f'· {category}')\n"
   ],
   "id": "3438fcd1a2aa0b74",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "sorted_visit_count = dict(sorted(visit_count.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "with open('general_tree.json', 'w') as file:\n",
    "    file.write(json.dumps(general_tree, indent=4))\n",
    "\n",
    "with open('general_tree_visit_counts.json', 'w') as file:\n",
    "    file.write(json.dumps(sorted_visit_count, indent=4))\n"
   ],
   "id": "50cf7585c5ad8ba4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "papermill": {
     "duration": 0.006578,
     "end_time": "2024-12-12T16:26:36.033922",
     "exception": false,
     "start_time": "2024-12-12T16:26:36.027344",
     "status": "completed"
    },
    "tags": []
   },
   "cell_type": "markdown",
   "source": [
    "## 3. Exploratory Data Analysis (EDA)\n",
    "Let's analyze the dataset and gain insights into its distribution.\n"
   ],
   "id": "fbcb95f4"
  },
  {
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T16:26:36.049527Z",
     "iopub.status.busy": "2024-12-12T16:26:36.048702Z",
     "iopub.status.idle": "2024-12-12T16:26:36.055194Z",
     "shell.execute_reply": "2024-12-12T16:26:36.054004Z"
    },
    "papermill": {
     "duration": 0.016586,
     "end_time": "2024-12-12T16:26:36.057289",
     "exception": false,
     "start_time": "2024-12-12T16:26:36.040703",
     "status": "completed"
    },
    "tags": []
   },
   "cell_type": "code",
   "source": [
    "print('At macro categories are:')\n",
    "for category in list(general_tree.keys()):\n",
    "    print(f'· {category}')\n"
   ],
   "id": "6865c633",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "For the goal of the project, the categories of interest are:\n",
    "1. computer security/network security\n",
    "2. computer security/antivirus and malware\n",
    "3. operating systems/mac os\n",
    "4. operating systems/windows\n",
    "5. operating systems/unix\n",
    "6. operating systems/linux\n",
    "7. software\n",
    "8. programming languages, included in software\n",
    "9. software/databases\n",
    "10. hardware\n",
    "11. electronic components, included in hardware\n",
    "12. hardware/computer/servers\n",
    "13. hardware/computer/portable computer\n",
    "14. hardware/computer/desktop computer\n",
    "15. hardware/computer components\n",
    "16. hardware/computer networking/router\n",
    "17. hardware/computer networking/wireless technology\n",
    "18. networking\n",
    "19. internet technology, included in networking\n"
   ],
   "id": "5b31409a7b0bd08"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "FIX_TARGETS = {\n",
    "    'computer security': 'computer security',\n",
    "    'operating systems': 'operating systems',\n",
    "    'software': 'software',\n",
    "    'programming languages': 'software',\n",
    "    'hardware': 'hardware',\n",
    "    'electronic components': 'hardware',\n",
    "    'networking': 'networking',\n",
    "    'internet technology': 'networking'\n",
    "}\n",
    "\n",
    "chosen_categories = [\n",
    "    list(set(FIX_TARGETS.keys()) & set(s))\n",
    "    for s in threat_tweets['watson_list']\n",
    "]\n",
    "\n",
    "for i, watson_list in enumerate(chosen_categories):\n",
    "    temp = list(set([FIX_TARGETS[c] for c in watson_list]))\n",
    "    if len(temp) < 1:\n",
    "        temp = ['other']\n",
    "    chosen_categories[i] = temp\n",
    "\n",
    "threat_tweets['target'] = chosen_categories\n",
    "\n",
    "threat_tweets.head()\n"
   ],
   "id": "287e815d832565fd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "X = preprocess_texts(\n",
    "    list_str=threat_tweets['text'],\n",
    "    model_path=GLOVE_6B_300D_TXT,\n",
    "    embedding_dim=300\n",
    ")\n"
   ],
   "id": "766b6469058b1f2e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "papermill": {
     "duration": 0.00674,
     "end_time": "2024-12-12T16:26:36.126427",
     "exception": false,
     "start_time": "2024-12-12T16:26:36.119687",
     "status": "completed"
    },
    "tags": []
   },
   "cell_type": "markdown",
   "source": [
    "## 4. Model Training\n",
    "\n",
    "We will now train different models and evaluate their performance.\n"
   ],
   "id": "30e50fa8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "br = None\n",
    "clr = None\n",
    "cc = None\n",
    "lp = None\n",
    "pst = None\n",
    "cdn = None\n",
    "mbr = None\n",
    "\n",
    "if Path('models/br.pkl').exists():\n",
    "    br = joblib.load('models/br.pkl')\n",
    "\n",
    "if Path('models/clr.pkl').exists():\n",
    "    clr = joblib.load('models/clr.pkl')\n",
    "\n",
    "if Path('models/cc.pkl').exists():\n",
    "    cc = joblib.load('models/cc.pkl')\n",
    "\n",
    "if Path('models/lp.pkl').exists():\n",
    "    lp = joblib.load('models/lp.pkl')\n",
    "\n",
    "if Path('models/pst.pkl').exists():\n",
    "    pst = joblib.load('models/pst.pkl')\n",
    "\n",
    "if Path('models/cdn.pkl').exists():\n",
    "    cdn = joblib.load('models/cdn.pkl')\n",
    "\n",
    "if Path('models/ensembles/meta_binary_relevance.pkl').exists():\n",
    "    mbr = joblib.load('models/ensembles/meta_binary_relevance.pkl')\n"
   ],
   "id": "e7b6c270783cb110",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T16:26:36.261035Z",
     "iopub.status.busy": "2024-12-12T16:26:36.260618Z",
     "iopub.status.idle": "2024-12-12T16:27:16.804071Z",
     "shell.execute_reply": "2024-12-12T16:27:16.802740Z"
    },
    "papermill": {
     "duration": 40.555062,
     "end_time": "2024-12-12T16:27:16.806882",
     "exception": false,
     "start_time": "2024-12-12T16:26:36.251820",
     "status": "completed"
    },
    "tags": []
   },
   "cell_type": "code",
   "source": [
    "mlb = MultiLabelBinarizer()\n",
    "y = mlb.fit_transform(y=threat_tweets['target'])\n",
    "\n",
    "unique_label_sets, threat_tweets['target mcc'] = np.unique(ar=y, axis=0, return_inverse=True)\n",
    "threat_tweets['target mcc pruned'], label_map_pst = prune_and_subsample(y, pruning_threshold=5, max_sub_samples=3)\n",
    "\n",
    "y_lp = threat_tweets['target mcc']\n",
    "y_pst = threat_tweets['target mcc pruned']\n",
    "\n",
    "label_map_lp = {i: tuple(lbl_set) for i, lbl_set in enumerate(unique_label_sets)}\n"
   ],
   "id": "62b61de3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T16:27:16.822984Z",
     "iopub.status.busy": "2024-12-12T16:27:16.822523Z",
     "iopub.status.idle": "2024-12-12T16:27:16.869712Z",
     "shell.execute_reply": "2024-12-12T16:27:16.868047Z"
    },
    "papermill": {
     "duration": 0.05826,
     "end_time": "2024-12-12T16:27:16.872512",
     "exception": false,
     "start_time": "2024-12-12T16:27:16.814252",
     "status": "completed"
    },
    "tags": []
   },
   "cell_type": "code",
   "source": [
    "X_train_val, y_train_val, X_test, y_test = iterative_train_test_split(\n",
    "    X=X,\n",
    "    y=y,\n",
    "    test_size=TEST_SIZE\n",
    ")\n",
    "\n",
    "X_train, y_train, X_val, y_val = iterative_train_test_split(\n",
    "    X=X_train_val,\n",
    "    y=y_train_val,\n",
    "    test_size=TEST_SIZE\n",
    ")\n"
   ],
   "id": "6f6e8f70",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "X_train_val_mcc, X_test_mcc, y_train_val_mcc, y_test_mcc = train_test_split(\n",
    "    X, y_lp,\n",
    "    test_size=TEST_SIZE,\n",
    "    random_state=RANDOM_STATE,\n",
    "    shuffle=True,\n",
    "    stratify=y_lp\n",
    ")\n",
    "\n",
    "X_train_mcc, X_val_mcc, y_train_mcc, y_val_mcc = train_test_split(\n",
    "    X_train_val_mcc, y_train_val_mcc,\n",
    "    test_size=TEST_SIZE,\n",
    "    random_state=RANDOM_STATE,\n",
    "    shuffle=True,\n",
    "    stratify=y_train_val_mcc\n",
    ")\n"
   ],
   "id": "4e0dee8cd7c2a8d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "X_train_val_mcc_pruned, X_test_mcc_pruned, y_train_val_mcc_pruned, y_test_mcc_pruned = train_test_split(\n",
    "    X, y_pst,\n",
    "    test_size=TEST_SIZE,\n",
    "    random_state=RANDOM_STATE,\n",
    "    shuffle=True,\n",
    "    stratify=y_pst\n",
    ")\n",
    "\n",
    "X_train_mcc_pruned, X_val_mcc_pruned, y_train_mcc_pruned, y_val_mcc_pruned = train_test_split(\n",
    "    X_train_val_mcc_pruned, y_train_val_mcc_pruned,\n",
    "    test_size=TEST_SIZE,\n",
    "    random_state=RANDOM_STATE,\n",
    "    shuffle=True,\n",
    "    stratify=y_train_val_mcc_pruned\n",
    ")\n"
   ],
   "id": "f425588b0234b556",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 4.1. Binary Problems\n",
   "id": "5497ccaa5c90acba"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 4.1.1. BR (Binary Relevance)\n",
   "id": "82dd9d2dcaa2fea4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if not br or OVERWRITE:\n",
    "    br = {}\n",
    "\n",
    "    for k in tqdm(BASE_CLASSIFIERS.keys()):\n",
    "        br[k] = OneVsRestClassifier(estimator=BASE_CLASSIFIERS[k]).fit(\n",
    "            X=X_train,\n",
    "            y=y_train\n",
    "        )\n",
    "\n",
    "    joblib.dump(br, 'models/br.pkl', compress=9)\n"
   ],
   "id": "edb485590d88fbc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 4.1.2. CLR (Calibrated Label Ranking)\n",
   "id": "c27df998bb1234c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if not clr or OVERWRITE:\n",
    "    clr = {}\n",
    "\n",
    "    for k, v in tqdm(BASE_CLASSIFIERS.items()):\n",
    "        model = CalibratedLabelRankClassifier(\n",
    "            classifier=v,\n",
    "            classes=mlb.classes_,\n",
    "            random_state=RANDOM_STATE\n",
    "        )\n",
    "\n",
    "        clr[k] = model.fit(\n",
    "            x=X_train,\n",
    "            y=[list(mlb.classes_[np.where(row == 1)[0]]) for row in y_train]\n",
    "        )\n",
    "\n",
    "    joblib.dump(clr, 'models/clr.pkl', compress=9)\n"
   ],
   "id": "16dc8d6169ac9f67",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 4.1.3. CC (Classifier Chains)\n",
   "id": "8032c9f1462962f2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if not cc or OVERWRITE:\n",
    "    cc = {}\n",
    "\n",
    "    for k, v in tqdm(BASE_CLASSIFIERS.items()):\n",
    "        model = ChainOfClassifiers(\n",
    "            classifier=v,\n",
    "            classes=mlb.classes_,\n",
    "            random_state=RANDOM_STATE\n",
    "        )\n",
    "\n",
    "        cc[k] = model.fit(\n",
    "            x=X_train,\n",
    "            y=y_train\n",
    "        )\n",
    "\n",
    "    joblib.dump(cc, 'models/cc.pkl', compress=9)\n"
   ],
   "id": "3162246646bc535f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 4.2. Multi-class Problems\n",
    "\n"
   ],
   "id": "80e25f22336640"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 4.2.1. LP (Label Powerset)\n",
   "id": "fba9c659bff8d6e3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if not lp or OVERWRITE:\n",
    "    lp = {}\n",
    "\n",
    "    for k, v in tqdm(BASE_CLASSIFIERS.items()):\n",
    "        model = LabelPowersetClassifier(\n",
    "            classifier=v,\n",
    "            label_map=label_map_lp,\n",
    "            random_state=RANDOM_STATE\n",
    "        )\n",
    "\n",
    "        lp[k] = model.fit(\n",
    "            x=X_train_mcc,\n",
    "            y=y_train_mcc\n",
    "        )\n",
    "\n",
    "    joblib.dump(lp, 'models/lp.pkl', compress=9)\n"
   ],
   "id": "838f03de34100d4b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 4.2.2. PSt (Pruned Sets)\n",
   "id": "36a35690f78685cb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if not pst or OVERWRITE:\n",
    "    pst = {}\n",
    "\n",
    "    for k, v in tqdm(BASE_CLASSIFIERS.items()):\n",
    "        model = LabelPowersetClassifier(\n",
    "            classifier=v,\n",
    "            label_map=label_map_pst,\n",
    "            random_state=RANDOM_STATE\n",
    "        )\n",
    "\n",
    "        pst[k] = model.fit(\n",
    "            x=X_train_mcc_pruned,\n",
    "            y=y_train_mcc_pruned\n",
    "        )\n",
    "\n",
    "    joblib.dump(pst, 'models/pst.pkl', compress=9)\n"
   ],
   "id": "df8604ee1c6ccc0c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 4.3. Ensembles\n",
   "id": "664c1fa64743bda8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 4.3.1. CDN (Conditional Dependency Network)\n",
   "id": "834fb6fe571b907f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if not cdn or OVERWRITE:\n",
    "    cdn = {}\n",
    "\n",
    "    for k, v in tqdm(BASE_CLASSIFIERS.items()):\n",
    "        model = ConditionalDependencyNetwork(\n",
    "            classifier=v,\n",
    "            num_iterations=100,\n",
    "            burn_in=10\n",
    "        )\n",
    "\n",
    "        cdn[k] = model.fit(\n",
    "            x=X_train,\n",
    "            y=y_train\n",
    "        )\n",
    "\n",
    "    joblib.dump(cdn, 'models/cdn.pkl', compress=9)\n"
   ],
   "id": "b50723c7780a738f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 4.3.2. MBR (Meta-Binary Relevance)\n",
   "id": "53f16754ed03d5ad"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if not mbr or OVERWRITE:\n",
    "    mbr = {}\n",
    "\n",
    "    for k, v in tqdm(BASE_CLASSIFIERS.items()):\n",
    "        model = MetaBinaryRelevance(\n",
    "            classifier=v,\n",
    "            use_cross_val=True,\n",
    "            n_splits=5\n",
    "        )\n",
    "\n",
    "        mbr[k] = model.fit(\n",
    "            x=X_train,\n",
    "            y=y_train\n",
    "        )\n",
    "\n",
    "    joblib.dump(mbr, 'models/ensembles/meta_binary_relevance.pkl', compress=9)\n"
   ],
   "id": "241fe414f4eeffff",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 5. Model Evaluation\n",
    "\n",
    "Now that we've trained the models, let's evaluate them in more detail.\n"
   ],
   "id": "6e50f10e93df31f9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "evaluation = {\n",
    "    'BR': assess_models(\n",
    "        x=X_val,\n",
    "        y=y_val,\n",
    "        technique=br\n",
    "    ),\n",
    "    'CLR': assess_models(\n",
    "        x=X_val,\n",
    "        y=y_val,\n",
    "        technique=clr\n",
    "    ),\n",
    "    'CC': assess_models(\n",
    "        x=X_val,\n",
    "        y=y_val,\n",
    "        technique=cc\n",
    "    ),\n",
    "    'LP': assess_models(\n",
    "        x=X_val_mcc,\n",
    "        y=np.array([list(label_map_lp[yp]) for yp in y_val_mcc]),\n",
    "        technique=lp\n",
    "    ),\n",
    "    'PST': assess_models(\n",
    "        x=X_val_mcc_pruned,\n",
    "        y=np.array([list(label_map_pst[yp]) for yp in y_val_mcc_pruned]),\n",
    "        technique=pst\n",
    "    ),\n",
    "    'CDN' : assess_models(\n",
    "        x=X_val,\n",
    "        y=y_val,\n",
    "        technique=cdn\n",
    "    ),\n",
    "    'MBR': assess_models(\n",
    "        x=X_val,\n",
    "        y=y_val,\n",
    "        technique=mbr\n",
    "    )\n",
    "}\n"
   ],
   "id": "4c0f3330656f697b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "performances = pd.DataFrame(evaluation).T\n",
    "performances\n"
   ],
   "id": "450b7af68d19a9b5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "z = evaluation['LP']['Model'].predict(X_val_mcc)\n",
    "acc = accuracy_score(np.array([list(label_map_lp[yp]) for yp in y_val_mcc]), z)\n",
    "\n",
    "print(classification_report(y_true=np.array([list(label_map_lp[yp]) for yp in y_val_mcc]), y_pred=z, target_names=mlb.classes_, zero_division=0))\n",
    "print(acc)"
   ],
   "id": "411837f42eb96c63",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 870709,
     "sourceId": 1483651,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4678553,
     "sourceId": 7954760,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30804,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 5394.913296,
   "end_time": "2024-12-12T17:56:06.436689",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-12-12T16:26:11.523393",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
